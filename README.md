
Certainly! Here's a complete README file incorporating all the provided scripts and functionalities:

---

# Talking with PDFs ðŸ¤–

## Overview
This project implements a Streamlit-based chatbot interface that allows users to interact with PDF documents. The chatbot utilizes natural language processing and AI to provide context-aware responses based on user queries and document content. PDF files uploaded by users are processed to create embeddings and stored in a Chroma vector store for efficient retrieval and querying.

## Features
- **Upload PDF Files**: Users can upload PDF files through a Streamlit interface.
- **Document Processing**: PDF documents are split into chunks and stored using a Chroma vector store.
- **Querying**: Users can enter queries to retrieve relevant information from uploaded PDFs.
- **Response Generation**: Responses are generated using the OpenAI Llama 3 language model based on the queried information and stored document contexts.

## Project Structure
- **app.py**: Main application script using Streamlit for user interface and interaction.
- **database.py**: Script for managing PDF document processing, chunking, and storage in Chroma vector store.
- **query.py**: Script for querying the Chroma vector store and generating responses using Llama 3.
- **get_embedding_function.py**: Function to obtain embeddings using OllamaEmbeddings from langchain_community.
- **requirements.txt**: List of Python dependencies required to run the project.

## Setup Instructions
1. **Clone the Repository:**
   ```bash
   git clone <repository-url>
   cd <repository-name>
   ```

2. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Application:**
   ```bash
   streamlit run app.py
   ```
   Open your web browser and navigate to `localhost:8501` to interact with the chatbot.

## Database Management
The project includes scripts to manage the Chroma vector store for efficient storage and retrieval of document embeddings.

### Database Update Script (`update_database.py`)
The `update_database.py` script manages the backend storage and retrieval of PDF document chunks. It uses the Chroma vector store to store vector embeddings and allows for dynamic updating of the database as new documents are added or existing ones are updated.

### Embedding Function (`get_embedding_function.py`)
The `get_embedding_function.py` script provides an embedding function using OllamaEmbeddings from langchain_community. This function generates embeddings for document chunks based on the "mxbai-embed-large" model, suitable for storing and retrieving document information efficiently within the Chroma vector store.

### Query Script (`query.py`)
The `query.py` script facilitates querying and retrieving information from the Chroma vector store. It uses the Ollama language model to generate context-aware responses based on user queries and retrieved document contexts.

## Usage
- Upload a PDF file using the provided interface in `app.py`.
- Enter queries to retrieve relevant information from the uploaded PDFs.
- View context-aware responses generated by the Llama 3 language model.

---

This README file provides a comprehensive overview of your project, including setup instructions, project structure, database management details, and usage guidelines. Adjust the paths, descriptions, and sections as per your specific project setup and requirements.
